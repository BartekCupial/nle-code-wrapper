agent: 
  type: naive            # Type of agent to use (e.g., 'naive', 'icl', 'cot', etc.)
  remember_cot: True     # Whether the agent should remember its reasoning across turns
  max_history: 16        # Maximum number of previous turns to keep in the dialogue history
  max_image_history: 0   # Maximum number of images to keep in the history
  max_cot_history: 1     # Maximum number of chain-of-thought steps to keep in history (if using 'cot' type of agent)
  cache_icl: False       # Whether to cache In-Context Learning demonstrations (for 'icl' agents)

eval:
  output_dir: "results"  # Directory where evaluation results will be saved
  resume_from: null      # Path to to the incomplete results file to resume an incomplete run
  num_workers: 16        # Number of parallel workers. Increase for faster evaluation if you have enough resources
  num_episodes:          # Minimum number of episodes to run for each environment. You can optionally increase this to get more reliable results
    minihack: 1          # Number of episodes for each 'minihack' task
  max_steps_per_episode: null   # Max steps per episode; null uses the environment default
  save_trajectories: True       # Whether to save agent trajectories
  icl_episodes: 1               # Number of In-Context Learning episodes to use
  icl_dataset: demos            # Dataset for ICL demonstrations

  wandb_save: False  
             
wandb:
  project_name: nle_code_wrapper
  entity_name: jtuyls
  run_name: null  

client:
  client_name: openai           # LLM client to use (e.g., 'openai', 'gemini', 'claude')
  model_id: gpt-4o              # Model identifier (e.g., 'gpt-4', 'gpt-3.5-turbo')
  base_url: http://localhost:8000/v1   # Base URL for the API (if using a local server)
  generate_kwargs:
    temperature: 0.0            # Sampling temperature; 0.0 makes the output deterministic
    max_tokens: 1024            # Max tokens to generate in the response
  timeout: 60                   # Timeout for API requests in seconds
  max_retries: 5                # Max number of retries for failed API calls
  delay: 2                      # Exponential backoff factor between retries in seconds

envs:
  names: minihack   # Environments to evaluate, separated by hyphens
  env_kwargs:
    seed: null                # Random seed; null means a random seed is used
  minihack_kwargs: 
    character: "@"
    max_episode_steps: 100
    penalty_step: -0.01         
    penalty_time: 0.0           
    penalty_mode: constant      
    savedir: null
    save_ttyrec_every: 0
    autopickup: False           
    skip_more: False

tasks:
  minihack_tasks:
    - "MiniHack-Corridor-R3-v0"

hydra:
  run:
    dir: .                     # Set the working directory to the current directory
  output_subdir: null          # Do not use an output subdirectory